% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={DATA 607: Week 10 Assignment},
  pdfauthor={Waheeb Algabri and Farhana Akther},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{DATA 607: Week 10 Assignment}
\author{Waheeb Algabri and Farhana Akther}
\date{}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

For this assignment, we will be exploring and building off of the code
presented in chapter 2 of the web textbook,
\href{https://www.tidytextmining.com/sentiment.html}{Text Mining with
R}.The first part of this assignment is taken directly from the book
example code. From there, we will be Working with a different corpus of
our choosing, and Incorporate at least one additional sentiment lexicon
which we can discover through research (potentially from another R
package).

\hypertarget{loading-required-libraries}{%
\paragraph{Loading Required
Libraries}\label{loading-required-libraries}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --
## v dplyr     1.1.0     v readr     2.1.4
## v forcats   1.0.0     v stringr   1.5.0
## v ggplot2   3.4.1     v tibble    3.1.8
## v lubridate 1.9.2     v tidyr     1.3.0
## v purrr     1.0.1     
## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
## i Use the ]8;;http://conflicted.r-lib.org/conflicted package]8;; to force all conflicts to become errors
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidytext)}
\FunctionTok{library}\NormalTok{(textdata)}
\FunctionTok{library}\NormalTok{(janeaustenr)}
\FunctionTok{library}\NormalTok{(wordcloud)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: RColorBrewer
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reshape2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'reshape2'
## 
## The following object is masked from 'package:tidyr':
## 
##     smiths
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gutenbergr)}
\FunctionTok{library}\NormalTok{(openintro)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: airports
## Loading required package: cherryblossom
## Loading required package: usdata
## 
## Attaching package: 'openintro'
## 
## The following object is masked from 'package:reshape2':
## 
##     tips
\end{verbatim}

\hypertarget{the-sentiment-datasets}{%
\section{The Sentiment Datasets}\label{the-sentiment-datasets}}

Obtain sentiment lexicons from three different sources: AFINN, Bing, and
NRC.

\textbf{Note}: If you initially encounter problems loading AFINN, bing,
or nrc, you will need to accept the license for the lexicon by typing in
the console for R Markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{afinn}\OtherTok{\textless{}{-}} \FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"afinn"}\NormalTok{)}
\NormalTok{bing}\OtherTok{\textless{}{-}} \FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"bing"}\NormalTok{)}
\NormalTok{nrc}\OtherTok{\textless{}{-}}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"nrc"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{code-example-from-text-book}{%
\section{Code Example From Text
Book}\label{code-example-from-text-book}}

\hypertarget{sentiment-analysis-with-inner-join}{%
\subsection{Sentiment Analysis with Inner
Join}\label{sentiment-analysis-with-inner-join}}

in the code below, we use the \texttt{austen\_books()} function from the
\texttt{janeaustenr} package to extract text from Jane Austen's novels
and prepare it for analysis by splitting it into individual words using
the \texttt{unnest\_tokens()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_books }\OtherTok{\textless{}{-}} \FunctionTok{austen\_books}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(book) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{linenumber =} \FunctionTok{row\_number}\NormalTok{(),}
    \AttributeTok{chapter =} \FunctionTok{cumsum}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(text, }
                                \FunctionTok{regex}\NormalTok{(}\StringTok{"\^{}chapter [}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{divxlc]"}\NormalTok{, }
                                      \AttributeTok{ignore\_case =} \ConstantTok{TRUE}\NormalTok{)))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{unnest\_tokens}\NormalTok{(word, text)}
\end{Highlighting}
\end{Shaded}

Next, we filter the NRC sentiment lexicon to include only words with a
``joy'' sentiment, then use the \texttt{inner\_join()} function to merge
this lexicon with the tidy text data frame. The resulting data frame is
then filtered to include only words from ``Emma'' and is counted using
\texttt{count()} to show the frequency of words with a ``joy''
sentiment.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nrc\_joy }\OtherTok{\textless{}{-}} \FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"nrc"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(sentiment }\SpecialCharTok{==} \StringTok{"joy"}\NormalTok{)}

\NormalTok{tidy\_books }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(book }\SpecialCharTok{==} \StringTok{"Emma"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(nrc\_joy) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(word, }\AttributeTok{sort =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{verbatim}
## # A tibble: 301 x 2
##    word          n
##    <chr>     <int>
##  1 good        359
##  2 friend      166
##  3 hope        143
##  4 happy       125
##  5 love        117
##  6 deal         92
##  7 found        92
##  8 present      89
##  9 kind         82
## 10 happiness    76
## # ... with 291 more rows
\end{verbatim}

Now, we join the tidy text data frame with the Bing sentiment lexicon
using \texttt{inner\_join()}. We then use \texttt{count()} and
\texttt{pivot\_wider()} functions to count the number of positive and
negative words in each book, grouped by sections of 80 lines. Finally,
the \texttt{ggplot()} function is used to create bar charts that show
the sentiment score over the plot trajectory of each novel. The chart is
facet-wrapped by book, and the sentiment score is calculated as the
difference between the number of positive and negative words.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{jane\_austen\_sentiment }\OtherTok{\textless{}{-}}\NormalTok{ tidy\_books }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"bing"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(book, }\AttributeTok{index =}\NormalTok{ linenumber }\SpecialCharTok{\%/\%} \DecValTok{80}\NormalTok{, sentiment) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ sentiment, }\AttributeTok{values\_from =}\NormalTok{ n, }\AttributeTok{values\_fill =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sentiment =}\NormalTok{ positive }\SpecialCharTok{{-}}\NormalTok{ negative)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{verbatim}
## Warning in inner_join(., get_sentiments("bing")): Each row in `x` is expected to match at most 1 row in `y`.
## i Row 435434 of `x` matches multiple rows.
## i If multiple matches are expected, set `multiple = "all"` to silence this
##   warning.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(jane\_austen\_sentiment, }\FunctionTok{aes}\NormalTok{(index, sentiment, }\AttributeTok{fill =}\NormalTok{ book)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{book, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free\_x"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Week-10-Team-Assignement-7_files/figure-latex/unnamed-chunk-5-1.pdf}

\hypertarget{comparing-the-three-sentiment-dictionaries}{%
\subsection{Comparing The Three Sentiment
Dictionaries}\label{comparing-the-three-sentiment-dictionaries}}

\begin{itemize}
\tightlist
\item
  Filter Data
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pride\_prejudice }\OtherTok{\textless{}{-}}\NormalTok{ tidy\_books }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(book }\SpecialCharTok{==} \StringTok{"Pride \& Prejudice"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Calculate Sentiment Scores
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{afinn }\OtherTok{\textless{}{-}}\NormalTok{ pride\_prejudice }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{inner\_join}\NormalTok{(}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"afinn"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(}\AttributeTok{index =}\NormalTok{ linenumber }\SpecialCharTok{\%/\%} \DecValTok{80}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{sentiment =} \FunctionTok{sum}\NormalTok{(value)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{method =} \StringTok{"AFINN"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bing\_and\_nrc }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(}
\NormalTok{  pride\_prejudice }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{inner\_join}\NormalTok{(}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"bing"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{method =} \StringTok{"Bing et al."}\NormalTok{),}
\NormalTok{  pride\_prejudice }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{inner\_join}\NormalTok{(}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"nrc"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                 \FunctionTok{filter}\NormalTok{(sentiment }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"positive"}\NormalTok{, }
                                         \StringTok{"negative"}\NormalTok{))}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{method =} \StringTok{"NRC"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(method, }\AttributeTok{index =}\NormalTok{ linenumber }\SpecialCharTok{\%/\%} \DecValTok{80}\NormalTok{, sentiment) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ sentiment,}
              \AttributeTok{values\_from =}\NormalTok{ n,}
              \AttributeTok{values\_fill =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sentiment =}\NormalTok{ positive }\SpecialCharTok{{-}}\NormalTok{ negative)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{verbatim}
## Warning in inner_join(., get_sentiments("nrc") %>% filter(sentiment %in% : Each row in `x` is expected to match at most 1 row in `y`.
## i Row 215 of `x` matches multiple rows.
## i If multiple matches are expected, set `multiple = "all"` to silence this
##   warning.
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Visualize Sentiment Scores
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bind\_rows}\NormalTok{(afinn, }
\NormalTok{          bing\_and\_nrc) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(index, sentiment, }\AttributeTok{fill =}\NormalTok{ method)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{method, }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free\_y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Week-10-Team-Assignement-7_files/figure-latex/unnamed-chunk-8-1.pdf}

\hypertarget{most-common-positive-and-negative-words}{%
\subsection{Most Common Positive and Negative
Words}\label{most-common-positive-and-negative-words}}

Counts the frequency of words in a text dataset categorized by sentiment
using the bing lexicon

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bing\_word\_counts }\OtherTok{\textless{}{-}}\NormalTok{ tidy\_books }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"bing"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(word, sentiment, }\AttributeTok{sort =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{verbatim}
## Warning in inner_join(., get_sentiments("bing")): Each row in `x` is expected to match at most 1 row in `y`.
## i Row 435434 of `x` matches multiple rows.
## i If multiple matches are expected, set `multiple = "all"` to silence this
##   warning.
\end{verbatim}

Visualizes the top 10 positive and negative words using the bing lexicon
in a bar plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bing\_word\_counts }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(sentiment) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice\_max}\NormalTok{(n, }\AttributeTok{n =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{word =} \FunctionTok{reorder}\NormalTok{(word, n)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(n, word, }\AttributeTok{fill =}\NormalTok{ sentiment)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{sentiment, }\AttributeTok{scales =} \StringTok{"free\_y"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Contribution to sentiment"}\NormalTok{,}
       \AttributeTok{y =} \ConstantTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Week-10-Team-Assignement-7_files/figure-latex/unnamed-chunk-10-1.pdf}

Creates a custom list of stop words that includes the words ``well'',
````, and''miss'' by binding together a tibble of these words with the
standard list of stop words.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{custom\_stop\_words }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(}\FunctionTok{tibble}\NormalTok{(}\AttributeTok{word =} \FunctionTok{c}\NormalTok{(}\StringTok{"well"}\NormalTok{, }\StringTok{""}\NormalTok{, }\StringTok{"miss"}\NormalTok{),  }
                                      \AttributeTok{lexicon =} \FunctionTok{c}\NormalTok{(}\StringTok{"custom"}\NormalTok{)), }
\NormalTok{                               stop\_words)}
\end{Highlighting}
\end{Shaded}

\hypertarget{corpus}{%
\section{Corpus}\label{corpus}}

\textbf{\emph{My Bondage and My Freedom} by Frederick Douglass}

We looked for the book by its ID number in the project Gutenberg
\href{https://www.gutenberg.org}{project Gutenberg}

We will analyze text \textbf{My Bondage and My Freedom},
autobiographical slave narrative by Frederick Douglass. We will use the
\emph{gutenbergr} library to search and download it.

\hypertarget{the-sentiment-dataset}{%
\subsection{The Sentiment Dataset}\label{the-sentiment-dataset}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bondage\_count }\OtherTok{\textless{}{-}} \FunctionTok{gutenberg\_download}\NormalTok{(}\DecValTok{202}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Determining mirror for Project Gutenberg from https://www.gutenberg.org/robot/harvest
\end{verbatim}

\begin{verbatim}
## Using mirror http://aleph.gutenberg.org
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bondage\_count}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 12,324 x 2
##    gutenberg_id text                                                            
##           <int> <chr>                                                           
##  1          202 "MY BONDAGE and MY FREEDOM"                                     
##  2          202 ""                                                              
##  3          202 "By Frederick Douglass"                                         
##  4          202 ""                                                              
##  5          202 ""                                                              
##  6          202 "By a principle essential to Christianity, a PERSON is eternall~
##  7          202 "differenced from a THING; so that the idea of a HUMAN BEING,"  
##  8          202 "necessarily excludes the idea of PROPERTY IN THAT BEING. ‚ÄîCOLE~
##  9          202 ""                                                              
## 10          202 "Entered according to Act of Congress in 1855 by Frederick Doug~
## # ... with 12,314 more rows
\end{verbatim}

\hypertarget{tidying-the-works-of-frederick-douglass}{%
\subsection{Tidying the Works of Frederick
Douglass}\label{tidying-the-works-of-frederick-douglass}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#removing the first 763 rows of text which are table of contents}
\NormalTok{bondage\_count }\OtherTok{\textless{}{-}}\NormalTok{ bondage\_count[}\FunctionTok{c}\NormalTok{(}\DecValTok{763}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(bondage\_count)),]}

\CommentTok{\#using unnest\_tokens to have each line be broken into individual rows. }
\NormalTok{bondage }\OtherTok{\textless{}{-}}\NormalTok{ bondage\_count }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unnest\_tokens}\NormalTok{(word, text)}
\NormalTok{bondage}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 129,096 x 2
##    gutenberg_id word       
##           <int> <chr>      
##  1          202 chapter    
##  2          202 i          
##  3          202 _childhood_
##  4          202 place      
##  5          202 of         
##  6          202 birth      
##  7          202 character  
##  8          202 of         
##  9          202 the        
## 10          202 district   
## # ... with 129,086 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bondage\_index }\OtherTok{\textless{}{-}}\NormalTok{ bondage\_count }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(text }\SpecialCharTok{!=} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{linenumber =} \FunctionTok{row\_number}\NormalTok{(),}
         \AttributeTok{chapter =} \FunctionTok{cumsum}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(text, }\FunctionTok{regex}\NormalTok{(}\StringTok{"(?\textless{}=Chapter )([}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{dII]\{1,3\})"}\NormalTok{, }\AttributeTok{ignore\_case =}  \ConstantTok{TRUE}\NormalTok{)))) }
\NormalTok{bondage\_index}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10,716 x 4
##    gutenberg_id text                                             linen~1 chapter
##           <int> <chr>                                              <int>   <int>
##  1          202 CHAPTER I. _Childhood_                                 1       1
##  2          202 PLACE OF BIRTH‚ÄîCHARACTER OF THE DISTRICT‚ÄîTUCKAH~       2       1
##  3          202 NAME‚ÄîCHOPTANK RIVER‚ÄîTIME OF BIRTH‚ÄîGENEALOGICAL ~       3       1
##  4          202 TIME‚ÄîNAMES OF GRANDPARENTS‚ÄîTHEIR POSITION‚ÄîGRAND~       4       1
##  5          202 ESTEEMED‚Äî‚ÄúBORN TO GOOD LUCK‚Äù‚ÄîSWEET POTATOES‚ÄîSUP~       5       1
##  6          202 CABIN‚ÄîITS CHARMS‚ÄîSEPARATING CHILDREN‚ÄîMY AUNTS‚ÄîT~       6       1
##  7          202 KNOWLEDGE OF BEING A SLAVE‚ÄîOLD MASTER‚ÄîGRIEFS AN~       7       1
##  8          202 CHILDHOOD‚ÄîCOMPARATIVE HAPPINESS OF THE SLAVE-BO~       8       1
##  9          202 SLAVEHOLDER.                                           9       1
## 10          202 In Talbot county, Eastern Shore, Maryland, near~      10       1
## # ... with 10,706 more rows, and abbreviated variable name 1: linenumber
\end{verbatim}

\hypertarget{sentiment-analysis-with-inner-join-1}{%
\subsection{Sentiment Analysis With Inner
Join}\label{sentiment-analysis-with-inner-join-1}}

\hypertarget{most-frequent-positive-words}{%
\subsubsection{Most Frequent Positive
Words}\label{most-frequent-positive-words}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bondage }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{inner\_join}\NormalTok{(}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"bing"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(sentiment }\SpecialCharTok{==} \StringTok{"positive"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(word, sentiment, }\AttributeTok{sort =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{10}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{word =} \FunctionTok{reorder}\NormalTok{(word, }\FunctionTok{desc}\NormalTok{(n))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ word, }\AttributeTok{y =}\NormalTok{ n) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Most Frequent Positive Words"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Count"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Word"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ n, }\AttributeTok{vjust =} \SpecialCharTok{{-}}\NormalTok{.}\DecValTok{5}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{panel.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"white"}\NormalTok{, }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{),}
    \AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{(), }
    \AttributeTok{axis.ticks.y =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{verbatim}
## Warning in inner_join(., get_sentiments("bing")): Each row in `x` is expected to match at most 1 row in `y`.
## i Row 5334 of `x` matches multiple rows.
## i If multiple matches are expected, set `multiple = "all"` to silence this
##   warning.
\end{verbatim}

\begin{verbatim}
## Selecting by n
\end{verbatim}

\includegraphics{Week-10-Team-Assignement-7_files/figure-latex/unnamed-chunk-14-1.pdf}

\hypertarget{most-frequent-negative-words}{%
\subsubsection{Most Frequent Negative
Words}\label{most-frequent-negative-words}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bondage }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{inner\_join}\NormalTok{(}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"bing"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(sentiment }\SpecialCharTok{==} \StringTok{"negative"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(word, sentiment, }\AttributeTok{sort =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{10}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{word =} \FunctionTok{reorder}\NormalTok{(word, }\FunctionTok{desc}\NormalTok{(n))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ word, }\AttributeTok{y =}\NormalTok{ n) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Most Frequent Negative Words"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Count"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Word"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ n, }\AttributeTok{vjust =} \SpecialCharTok{{-}}\NormalTok{.}\DecValTok{5}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{panel.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"white"}\NormalTok{, }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{),}
    \AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{(), }
    \AttributeTok{axis.ticks.y =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{verbatim}
## Warning in inner_join(., get_sentiments("bing")): Each row in `x` is expected to match at most 1 row in `y`.
## i Row 5334 of `x` matches multiple rows.
## i If multiple matches are expected, set `multiple = "all"` to silence this
##   warning.
\end{verbatim}

\begin{verbatim}
## Selecting by n
\end{verbatim}

\includegraphics{Week-10-Team-Assignement-7_files/figure-latex/unnamed-chunk-15-1.pdf}

\hypertarget{wordclouds}{%
\subsubsection{Wordclouds}\label{wordclouds}}

Let's look at the most common words in Frederick Douglasss's book with
wordcloud.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(RColorBrewer)}
\CommentTok{\# Color palette for the wordclouds}
\NormalTok{colors }\OtherTok{\textless{}{-}} \FunctionTok{brewer.pal}\NormalTok{(}\DecValTok{8}\NormalTok{, }\StringTok{"Dark2"}\NormalTok{)}
\CommentTok{\# Wordcloud of non{-}stopwords}
\NormalTok{bondage }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{anti\_join}\NormalTok{(stop\_words) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(word) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{with}\NormalTok{(}\FunctionTok{wordcloud}\NormalTok{(word, n, }\AttributeTok{max.words =} \DecValTok{100}\NormalTok{, }\AttributeTok{color =}\NormalTok{ colors))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{verbatim}
## Warning in strwidth(words[i], cex = size[i], ...): conversion failure on
## 'master‚Äôs' in 'mbcsToSbcs': dot substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in strwidth(words[i], cex = size[i], ...): conversion failure on
## 'master‚Äôs' in 'mbcsToSbcs': dot substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in strwidth(words[i], cex = size[i], ...): conversion failure on
## 'master‚Äôs' in 'mbcsToSbcs': dot substituted for <99>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : conversion failure on 'master‚Äôs' in 'mbcsToSbcs': dot substituted
## for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : conversion failure on 'master‚Äôs' in 'mbcsToSbcs': dot substituted
## for <80>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : conversion failure on 'master‚Äôs' in 'mbcsToSbcs': dot substituted
## for <99>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : font metrics unknown for Unicode character U+2019
\end{verbatim}

\begin{verbatim}
## Warning in strwidth(words[i], cex = size[i], ...): conversion failure on
## 'lloyd‚Äôs' in 'mbcsToSbcs': dot substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in strwidth(words[i], cex = size[i], ...): conversion failure on
## 'lloyd‚Äôs' in 'mbcsToSbcs': dot substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in strwidth(words[i], cex = size[i], ...): conversion failure on
## 'lloyd‚Äôs' in 'mbcsToSbcs': dot substituted for <99>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : conversion failure on 'lloyd‚Äôs' in 'mbcsToSbcs': dot substituted
## for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : conversion failure on 'lloyd‚Äôs' in 'mbcsToSbcs': dot substituted
## for <80>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : conversion failure on 'lloyd‚Äôs' in 'mbcsToSbcs': dot substituted
## for <99>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : font metrics unknown for Unicode character U+2019
\end{verbatim}

\begin{verbatim}
## Warning in strwidth(words[i], cex = size[i], ...): conversion failure on
## 'michael‚Äôs' in 'mbcsToSbcs': dot substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in strwidth(words[i], cex = size[i], ...): conversion failure on
## 'michael‚Äôs' in 'mbcsToSbcs': dot substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in strwidth(words[i], cex = size[i], ...): conversion failure on
## 'michael‚Äôs' in 'mbcsToSbcs': dot substituted for <99>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : conversion failure on 'michael‚Äôs' in 'mbcsToSbcs': dot substituted
## for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : conversion failure on 'michael‚Äôs' in 'mbcsToSbcs': dot substituted
## for <80>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : conversion failure on 'michael‚Äôs' in 'mbcsToSbcs': dot substituted
## for <99>
\end{verbatim}

\begin{verbatim}
## Warning in text.default(x1, y1, words[i], cex = size[i], offset = 0, srt =
## rotWord * : font metrics unknown for Unicode character U+2019
\end{verbatim}

\includegraphics{Week-10-Team-Assignement-7_files/figure-latex/unnamed-chunk-16-1.pdf}

Above the most common words in Frederick Douglasss's autobiographical
slave narrativ.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sentiment analysis to tag positive and negative words using an inner join, then find the most common positive and negative words}
\NormalTok{bondage }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"bing"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(word, sentiment, }\AttributeTok{sort =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{acast}\NormalTok{(word }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sentiment, }\AttributeTok{value.var =} \StringTok{"n"}\NormalTok{, }\AttributeTok{fill =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{comparison.cloud}\NormalTok{(}\AttributeTok{colors =}\NormalTok{ colors,}
                   \AttributeTok{max.words =} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{verbatim}
## Warning in inner_join(., get_sentiments("bing")): Each row in `x` is expected to match at most 1 row in `y`.
## i Row 5334 of `x` matches multiple rows.
## i If multiple matches are expected, set `multiple = "all"` to silence this
##   warning.
\end{verbatim}

\includegraphics{Week-10-Team-Assignement-7_files/figure-latex/unnamed-chunk-17-1.pdf}

The size of a word's text above is in proportion to its frequency within
its sentiment. We can use this visualization to see the most important
positive and negative words, but the sizes of the words are not
comparable across sentiments.

\hypertarget{loughran-sentiment-lexicon}{%
\section{Loughran Sentiment Lexicon}\label{loughran-sentiment-lexicon}}

We will use
\href{https://rdrr.io/cran/tidytext/man/get_sentiments.html}{loughran}
lexicon that we have researched.

\textbf{Note}: If you initially encounter problems loading loughran, you
will need to accept the license for the lexicon by typing in the console
for R Markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lghrn }\OtherTok{\textless{}{-}} \FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"loughran"}\NormalTok{)}
\FunctionTok{unique}\NormalTok{(lghrn}\SpecialCharTok{$}\NormalTok{sentiment)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "negative"     "positive"     "uncertainty"  "litigious"    "constraining"
## [6] "superfluous"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#let‚Äôs explore the lexicon to see what types of words are litigious and constraining.}
\NormalTok{bondage\_index }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{unnest\_tokens}\NormalTok{(word, text) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{inner\_join}\NormalTok{(}\FunctionTok{get\_sentiments}\NormalTok{(}\StringTok{"loughran"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(sentiment }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"litigious"}\NormalTok{, }\StringTok{"constraining"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(word, sentiment, }\AttributeTok{sort =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(sentiment) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{10}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{reorder}\NormalTok{(word,}\FunctionTok{desc}\NormalTok{(n)), }\AttributeTok{y =}\NormalTok{ n) }\SpecialCharTok{+} 
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{sentiment, }\AttributeTok{scales =} \StringTok{"free\_x"}\NormalTok{)  }\SpecialCharTok{+} 
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ n, }\AttributeTok{vjust =} \SpecialCharTok{{-}}\NormalTok{.}\DecValTok{5}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Words Associated with Litigious and Constraining"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Count"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Word"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{panel.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"white"}\NormalTok{, }\AttributeTok{color =} \ConstantTok{NA}\NormalTok{),}
    \AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{(), }
    \AttributeTok{axis.ticks.y =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(word)`
\end{verbatim}

\begin{verbatim}
## Warning in inner_join(., get_sentiments("loughran")): Each row in `x` is expected to match at most 1 row in `y`.
## i Row 881 of `x` matches multiple rows.
## i If multiple matches are expected, set `multiple = "all"` to silence this
##   warning.
\end{verbatim}

\begin{verbatim}
## Selecting by n
\end{verbatim}

\includegraphics{Week-10-Team-Assignement-7_files/figure-latex/unnamed-chunk-18-1.pdf}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

This assignment has allowed us to explore the topic of sentiment
analysis. We have successfully implemented and expanded upon the main
example code from chapter 2 of the Text Mining with R book. We have used
three different sentiment lexicons: `AFINN', `bing', and `nrc' to
analyze the sentiment of Jane Austen's novels. Further, by using the
`gutenbergr' library we have explored the ``My Bondage and My Freedom''
by Frederick Douglass. We have tidied the dataset with one-token-per-row
by using the unnest\_tokens () function. We have used our sentiment
analysis with inner join to be able to find the most frequent positive
words and most frequent negative words. From our findings, we can see
the respective most frequent positive and negative words are
\textbf{master} and \textbf{slave}. These two words are also look like
the most common words using wordcloud. Moreover, we filter the
`loughran' sentiment lexicon to include only words with a ``litigious''
and ``constraining'' sentiment. The resulting data frame is then
filtered to include only words from ``bondage'' and is counted using
count () to show the frequency of words with a ``litigious'' and
``constraining'' sentiments.From here, we can see that the words
associated with litigious results are more than constraining.

\end{document}
